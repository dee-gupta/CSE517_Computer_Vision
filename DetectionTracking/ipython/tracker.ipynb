{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#face_cascade = cv2.CascadeClassifier('/usr/local/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml')\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def help_message():\n",
    "   print(\"Usage: [Question_Number] [Input_Video] [Output_Directory]\")\n",
    "   print(\"[Question Number]\")\n",
    "   print(\"1 Camshift\")\n",
    "   print(\"2 Particle Filter\")\n",
    "   print(\"3 Kalman Filter\")\n",
    "   print(\"4 Optical Flow\")\n",
    "   print(\"[Input_Video]\")\n",
    "   print(\"Path to the input video\")\n",
    "   print(\"[Output_Directory]\")\n",
    "   print(\"Output directory\")\n",
    "   print(\"Example usages:\")\n",
    "   print(sys.argv[0] + \" 1 \" + \"02-1.avi \" + \"./\")\n",
    "\n",
    "def detect_one_face(im):\n",
    "    gray=cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 3)\n",
    "    if len(faces) == 0:\n",
    "        return (0,0,0,0)\n",
    "    return faces[0]\n",
    "\n",
    "def hsv_histogram_for_window(frame, window):\n",
    "    # set up the ROI for tracking\n",
    "    c,r,w,h = window\n",
    "    roi = frame[r:r+h, c:c+w]\n",
    "    hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "    roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "    cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "    return roi_hist\n",
    "\n",
    "\n",
    "def resample(weights):\n",
    "    n = len(weights)\n",
    "    indices = []\n",
    "    C = [0.] + [sum(weights[:i+1]) for i in range(n)]\n",
    "    u0, j = np.random.random(), 0\n",
    "    for u in [(u0+i)/n for i in range(n)]:\n",
    "      while u > C[j]:\n",
    "          j+=1\n",
    "      indices.append(j-1)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = cv2.VideoCapture(\"02-1 (Converted).mov\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mycamshift(file_name):\n",
    "    # Open output file\n",
    "    output_name = \"./\"+file_name\n",
    "    output = open(output_name,\"w\")\n",
    "\n",
    "    frameCounter = 0\n",
    "    # read first frame\n",
    "    ret ,frame = v.read()\n",
    "    if ret == False:\n",
    "        return\n",
    "\n",
    "    # detect face in first frame\n",
    "    c,r,w,h = detect_one_face(frame)\n",
    "\n",
    "    # Write track point for first frame\n",
    "    pt_x, pt_y = c + w / 2, r + h / 2\n",
    "    output.write(\"%d,%d,%d\\n\" % (0, pt_x, pt_y)) # Write as 0,pt_x,pt_y\n",
    "    frameCounter = frameCounter + 1\n",
    "\n",
    "    # set the initial tracking window\n",
    "    track_window = (c, r, w, h)\n",
    "\n",
    "    # calculate the HSV histogram in the window\n",
    "    roi_hist = hsv_histogram_for_window(frame, (c, r, w, h)) # this is provided for you\n",
    "\n",
    "    term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "    while(True):\n",
    "        ret, frame = v.read() # read another frame\n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "        #change colorspace to hsv\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        #calculating backprojection\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "\n",
    "        #meanshift to get new location\n",
    "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "\n",
    "        #drawing it on image\n",
    "        pts = cv2.boxPoints(ret)\n",
    "\n",
    "        pt_x = (pts[0][0] + pts[2][0]) / 2\n",
    "        pt_y = (pts[0][1] + pts[2][1]) / 2\n",
    "\n",
    "        # write the result to the output file\n",
    "        output.write(\"%d,%d,%d\\n\" % (frameCounter, pt_x, pt_y)) # Write as frame_index,pt_x,pt_y\n",
    "        frameCounter = frameCounter + 1\n",
    "\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'boxPoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-250af12922e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmycamshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output_camshift.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-6d455e61bae6>\u001b[0m in \u001b[0;36mmycamshift\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#drawing it on image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxPoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mpt_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'boxPoints'"
     ]
    }
   ],
   "source": [
    "mycamshift(\"output_camshift.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
